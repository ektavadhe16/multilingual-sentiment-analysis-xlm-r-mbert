{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yjvqCcmjvNud"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers datasets scikit-learn pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Geu4vJTmwDfy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/insta_data.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "df = df[[\"Post Description\", \"Sentiment\"]].dropna()\n",
        "\n",
        "print(df.head(), df[\"Sentiment\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOvb_ng3wNk1"
      },
      "outputs": [],
      "source": [
        "sentiment_mapping = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNUuxQKiwPug"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"Post Description\"] = df[\"Post Description\"].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uOJIsGZwVGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"Post Description\"], df[\"Sentiment\"], test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLqtqGwowYPo"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx6L73ACwg1m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, list(train_labels))\n",
        "test_dataset = SentimentDataset(test_encodings, list(test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHWCag4Awjsg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9HP7Yv-wl6B"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
        "model.to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-dt6Othxzka"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "num_training_steps = len(train_loader) * 6\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwlspP4ax2pl"
      },
      "outputs": [],
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "error_rate_history = []\n",
        "\n",
        "def train_model_with_tracking(model, dataloader, optimizer, scheduler, num_epochs=6):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.logits.argmax(dim=1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        accuracy = correct / total\n",
        "        error_rate = 1 - accuracy\n",
        "\n",
        "        train_loss_history.append(avg_loss)\n",
        "        train_accuracy_history.append(accuracy)\n",
        "        error_rate_history.append(error_rate)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wamOdrj2x45Q"
      },
      "outputs": [],
      "source": [
        "train_model_with_tracking(model, train_loader, optimizer, lr_scheduler, num_epochs=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDgGhtjBNQKo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-5Tp0oWX3lk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model_with_metrics(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_scores = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_scores.extend(logits.cpu().numpy())\n",
        "\n",
        "\n",
        "    class_labels = [\"positive\", \"neutral\", \"negative\"]\n",
        "    print(\"ðŸ“Š Accuracy per Class:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        class_total = sum(1 for y in y_true if y == i)\n",
        "        class_correct = sum(1 for y, p in zip(y_true, y_pred) if y == i and y == p)\n",
        "        class_acc = (class_correct / class_total) * 100 if class_total > 0 else 0\n",
        "        print(f\"  â€¢ {label.capitalize()}: {class_acc:.2f}%\")\n",
        "\n",
        "\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    print(f\"\\nâœ… Overall Accuracy: {overall_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(\"\\nðŸ“‹ Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    y_true_bin = np.eye(3)[y_true]\n",
        "    y_scores = np.array(y_scores)\n",
        "    for i, label in enumerate(class_labels):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
        "        plt.plot(fpr, tpr, label=f\"{label} (AUC = {auc(fpr, tpr):.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    specificity = np.mean([\n",
        "        cm[i, i] / (cm[:, i].sum() + cm[i, :].sum() - 2 * cm[i, i])\n",
        "        if (cm[:, i].sum() + cm[i, :].sum() - 2 * cm[i, i]) != 0 else 0\n",
        "        for i in range(3)\n",
        "    ])\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Macro Precision: {precision:.4f}\")\n",
        "    print(f\"ðŸ“ˆ Macro Recall (Sensitivity): {recall:.4f}\")\n",
        "    print(f\"ðŸ’¥ Macro F1 Score: {f1:.4f}\")\n",
        "    print(f\"ðŸ§  Macro Specificity (approx): {specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHVmWnLkX-iA"
      },
      "outputs": [],
      "source": [
        "evaluate_model_with_metrics(model, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}